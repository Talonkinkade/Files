{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YV_peOFwUQUt"
      },
      "source": [
        "# Using Opik with Anthropic\n",
        "\n",
        "Opik integrates with Anthropic to provide a simple way to log traces for all Anthropic LLM calls. This works for all supported models, including if you are using the streaming API.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrojdG8UUQUu"
      },
      "source": [
        "## Creating an account on Comet.com\n",
        "\n",
        "[Comet](https://www.comet.com/site?from=llm&utm_source=opik&utm_medium=colab&utm_content=anthropic&utm_campaign=opik) provides a hosted version of the Opik platform, [simply create an account](https://www.comet.com/signup?from=llm&utm_source=opik&utm_medium=colab&utm_content=anthropic&utm_campaign=opik) and grab your API Key.\n",
        "\n",
        "> You can also run the Opik platform locally, see the [installation guide](https://www.comet.com/docs/opik/self-host/overview/?from=llm&utm_source=opik&utm_medium=colab&utm_content=anthropic&utm_campaign=opik) for more information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8T1Oa2P-UQUv"
      },
      "outputs": [],
      "source": [
        "%pip install --upgrade opik anthropic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AcQOwfWFUQUv",
        "outputId": "a2d09a46-c5c1-4fd6-a548-d2444c261c75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'opik'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1-829153281.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mopik\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mopik\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muse_local\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'opik'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import opik\n",
        "\n",
        "opik.configure(use_local=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WoU10njUQUw"
      },
      "source": [
        "## Preparing our environment\n",
        "\n",
        "First, we will set up our anthropic client. You can [find or create your Anthropic API Key in this page page](https://console.anthropic.com/settings/keys) and paste it below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wGc1SC5bUQUw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import getpass\n",
        "import anthropic\n",
        "\n",
        "if \"ANTHROPIC_API_KEY\" not in os.environ:\n",
        "    os.environ[\"ANTHROPIC_API_KEY\"] = getpass.getpass(\"Enter your Anthropic API key: \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDUOk0sqUQUw"
      },
      "source": [
        "## Logging traces\n",
        "\n",
        "In order to log traces to Opik, we need to wrap our Anthropic calls with the `track_anthropic` function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r5DiX-nMUQUw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "from opik.integrations.anthropic import track_anthropic\n",
        "\n",
        "anthropic_client = anthropic.Anthropic()\n",
        "anthropic_client = track_anthropic(\n",
        "    anthropic_client, project_name=\"anthropic-integration-demo\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PHl6WUEuUQUw"
      },
      "outputs": [],
      "source": [
        "PROMPT = \"Why is it important to use a LLM Monitoring like CometML Opik tool that allows you to log traces and spans when working with Anthropic LLM Models?\"\n",
        "\n",
        "response = anthropic_client.messages.create(\n",
        "    model=\"claude-3-5-sonnet-20241022\",\n",
        "    max_tokens=1024,\n",
        "    messages=[{\"role\": \"user\", \"content\": PROMPT}],\n",
        ")\n",
        "print(\"Response\", response.content[0].text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVwwuosTUQUw"
      },
      "source": [
        "The prompt and response messages are automatically logged to Opik and can be viewed in the UI.\n",
        "\n",
        "![Anthropic Integration](https://raw.githubusercontent.com/comet-ml/opik/main/apps/opik-documentation/documentation/fern/img/cookbook/anthropic_trace_cookbook.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dn1mOz5UQUx"
      },
      "source": [
        "## Using it with the `track` decorator\n",
        "\n",
        "If you have multiple steps in your LLM pipeline, you can use the `track` decorator to log the traces for each step. If Anthropic is called within one of these steps, the LLM call with be associated with that corresponding step:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_IEDwCKUQUx"
      },
      "outputs": [],
      "source": [
        "import anthropic\n",
        "\n",
        "from opik import track\n",
        "from opik.integrations.anthropic import track_anthropic\n",
        "\n",
        "os.environ[\"OPIK_PROJECT_NAME\"] = \"anthropic-integration-demo\"\n",
        "\n",
        "anthropic_client = anthropic.Anthropic()\n",
        "anthropic_client = track_anthropic(anthropic_client)\n",
        "\n",
        "\n",
        "@track\n",
        "def generate_story(prompt):\n",
        "    res = anthropic_client.messages.create(\n",
        "        model=\"claude-3-5-sonnet-20241022\",\n",
        "        max_tokens=1024,\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    )\n",
        "    return res.content[0].text\n",
        "\n",
        "\n",
        "@track\n",
        "def generate_topic():\n",
        "    prompt = \"Generate a topic for a story about Opik.\"\n",
        "    res = anthropic_client.messages.create(\n",
        "        model=\"claude-3-5-sonnet-20241022\",\n",
        "        max_tokens=1024,\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    )\n",
        "    return res.content[0].text\n",
        "\n",
        "\n",
        "@track\n",
        "def generate_opik_story():\n",
        "    topic = generate_topic()\n",
        "    story = generate_story(topic)\n",
        "    return story\n",
        "\n",
        "\n",
        "generate_opik_story()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ec3BH7LyUQUx"
      },
      "source": [
        "The trace can now be viewed in the UI:\n",
        "\n",
        "![Anthropic Integration](https://raw.githubusercontent.com/comet-ml/opik/main/apps/opik-documentation/documentation/fern/img/cookbook/anthropic_trace_decorator_cookbook.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGW5tYMiUQUx"
      },
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}